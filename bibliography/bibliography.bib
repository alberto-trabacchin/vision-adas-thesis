@misc{coco,
      title={Microsoft COCO: Common Objects in Context}, 
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{kitti,
author = {A Geiger and P Lenz and C Stiller and R Urtasun},
title ={Vision meets robotics: The KITTI dataset},

journal = {The International Journal of Robotics Research},
volume = {32},
number = {11},
pages = {1231-1237},
year = {2013},
doi = {10.1177/0278364913491297},

URL = { 
    
        https://doi.org/10.1177/0278364913491297
    
    

},
eprint = { 
    
        https://doi.org/10.1177/0278364913491297
    
    

}
,
    abstract = { We present a novel dataset captured from a VW station wagon for use in mobile robotics and autonomous driving research. In total, we recorded 6 hours of traffic scenarios at 10–100 Hz using a variety of sensor modalities such as high-resolution color and grayscale stereo cameras, a Velodyne 3D laser scanner and a high-precision GPS/IMU inertial navigation system. The scenarios are diverse, capturing real-world traffic situations, and range from freeways over rural areas to inner-city scenes with many static and dynamic objects. Our data is calibrated, synchronized and timestamped, and we provide the rectified and raw image sequences. Our dataset also contains object labels in the form of 3D tracklets, and we provide online benchmarks for stereo, optical flow, object detection and other tasks. This paper describes our recording platform, the data format and the utilities that we provide. }
}

@misc{bdd100k,
      title={BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning}, 
      author={Fisher Yu and Haofeng Chen and Xin Wang and Wenqi Xian and Yingying Chen and Fangchen Liu and Vashisht Madhavan and Trevor Darrell},
      year={2020},
      eprint={1805.04687},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{waymo,
      title={Scalability in Perception for Autonomous Driving: Waymo Open Dataset}, 
      author={Pei Sun and Henrik Kretzschmar and Xerxes Dotiwalla and Aurelien Chouard and Vijaysai Patnaik and Paul Tsui and James Guo and Yin Zhou and Yuning Chai and Benjamin Caine and Vijay Vasudevan and Wei Han and Jiquan Ngiam and Hang Zhao and Aleksei Timofeev and Scott Ettinger and Maxim Krivokon and Amy Gao and Aditya Joshi and Sheng Zhao and Shuyang Cheng and Yu Zhang and Jonathon Shlens and Zhifeng Chen and Dragomir Anguelov},
      year={2020},
      eprint={1912.04838},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{nuscenes,
      title={nuScenes: A multimodal dataset for autonomous driving}, 
      author={Holger Caesar and Varun Bankiti and Alex H. Lang and Sourabh Vora and Venice Erin Liong and Qiang Xu and Anush Krishnan and Yu Pan and Giancarlo Baldan and Oscar Beijbom},
      year={2020},
      eprint={1903.11027},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{uricar2019challenges,
      title={Challenges in Designing Datasets and Validation for Autonomous Driving}, 
      author={Michal Uricar and David Hurych and Pavel Krizek and Senthil Yogamani},
      year={2019},
      eprint={1901.09270},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{retinatrack,
      title={RetinaTrack: Online Single Stage Joint Detection and Tracking}, 
      author={Zhichao Lu and Vivek Rathod and Ronny Votel and Jonathan Huang},
      year={2020},
      eprint={2003.13870},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{transtrack,
      title={TransTrack: Multiple Object Tracking with Transformer}, 
      author={Peize Sun and Jinkun Cao and Yi Jiang and Rufeng Zhang and Enze Xie and Zehuan Yuan and Changhu Wang and Ping Luo},
      year={2021},
      eprint={2012.15460},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{bytetrack,
      title={ByteTrack: Multi-Object Tracking by Associating Every Detection Box}, 
      author={Yifu Zhang and Peize Sun and Yi Jiang and Dongdong Yu and Fucheng Weng and Zehuan Yuan and Ping Luo and Wenyu Liu and Xinggang Wang},
      year={2022},
      eprint={2110.06864},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{alexnet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@misc{vggnet,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{inception,
      title={Going Deeper with Convolutions}, 
      author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
      year={2014},
      eprint={1409.4842},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{resnet,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{efficientnet,
      title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks}, 
      author={Mingxing Tan and Quoc V. Le},
      year={2020},
      eprint={1905.11946},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{vit,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{imagenet,
      title={ImageNet Large Scale Visual Recognition Challenge}, 
      author={Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
      year={2015},
      eprint={1409.0575},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{densenet,
      title={Densely Connected Convolutional Networks}, 
      author={Gao Huang and Zhuang Liu and Laurens van der Maaten and Kilian Q. Weinberger},
      year={2018},
      eprint={1608.06993},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@article{rnn,
title = {Serial order: a parallel distributed processing approach. Technical report, June 1985-March 1986},
author = {Jordan, M I},
abstractNote = {A theory of serial order is proposed that attempts to deal both with the classical problem of the temporal organization of internally generated action sequences as well as with certain of the parallel aspects of sequential behavior. The theory describes a dynamical system that is embodied as a parallel distributed processing or connectionist network. The trajectories of this dynamical system come to follow desired paths corresponding to particular action sequences as a result of a learning process during which constraints are imposed on the system. These constraints enforce sequentiality where necessary and, as they are relaxed, performance becomes more parallel. The theory is applied to the problem of coarticulation in speech production and simulation experiments are presented.},
doi = {},
url = {https://www.osti.gov/biblio/6910294},
place = {United States},
year = {1986},
month = {5}
}

@article{lstm,
    author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
    title = "{Long Short-Term Memory}",
    journal = {Neural Computation},
    volume = {9},
    number = {8},
    pages = {1735-1780},
    year = {1997},
    month = {11},
    abstract = "{Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}",
    issn = {0899-7667},
    doi = {10.1162/neco.1997.9.8.1735},
    url = {https://doi.org/10.1162/neco.1997.9.8.1735},
    eprint = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
}

@misc{gru,
      title={Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling}, 
      author={Junyoung Chung and Caglar Gulcehre and KyungHyun Cho and Yoshua Bengio},
      year={2014},
      eprint={1412.3555},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@misc{vivit,
      title={ViViT: A Video Vision Transformer}, 
      author={Anurag Arnab and Mostafa Dehghani and Georg Heigold and Chen Sun and Mario Lučić and Cordelia Schmid},
      year={2021},
      eprint={2103.15691},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@Article{ssl_survey,
author={van Engelen, Jesper E.
and Hoos, Holger H.},
title={A survey on semi-supervised learning},
journal={Machine Learning},
year={2020},
month=Feb,
day={01},
volume={109},
number={2},
pages={373-440},
issn={1573-0565},
doi={10.1007/s10994-019-05855-6},
url={https://doi.org/10.1007/s10994-019-05855-6}
}

@book{chapelle2010semi,
  title={Semi-supervised learning},
  author={Chapelle, O. and Sch{\"o}lkopf, B. and Zien, A.},
  year={2010},
  publisher={MIT Press}
}

@misc{pham2021meta,
      title={Meta Pseudo Labels}, 
      author={Hieu Pham and Zihang Dai and Qizhe Xie and Minh-Thang Luong and Quoc V. Le},
      year={2021},
      eprint={2003.10580},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{attention_is_all_you_need,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention Is All You Need},
  journal      = {CoRR},
  volume       = {abs/1706.03762},
  year         = {2017},
  url          = {http://arxiv.org/abs/1706.03762},
  eprinttype    = {arXiv},
  eprint       = {1706.03762},
  timestamp    = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{adas_report_2023,
  title        = {Automotive ADAS (Advanced Driver Assistance System) Market Outlook},
  author       = {Kaitwade, Nikhil},
  year         = 2023,
  month        = 11,
  howpublished = {Online},
  url          = {https://www.futuremarketinsights.com/reports/adas-market},
  note         = {Accessed: 2024-06-06}
}


@misc{dreyeve,
      title={Predicting the Driver's Focus of Attention: the DR(eye)VE Project}, 
      author={Andrea Palazzi and Davide Abati and Simone Calderara and Francesco Solera and Rita Cucchiara},
      year={2018},
      eprint={1705.03854},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{midas,
      title={Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer}, 
      author={René Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun},
      year={2020},
      eprint={1907.01341},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{sfm_self_calibration1,
   title={Hierarchical structure-and-motion recovery from uncalibrated images},
   volume={140},
   ISSN={1077-3142},
   url={http://dx.doi.org/10.1016/j.cviu.2015.05.011},
   DOI={10.1016/j.cviu.2015.05.011},
   journal={Computer Vision and Image Understanding},
   publisher={Elsevier BV},
   author={Toldo, Roberto and Gherardi, Riccardo and Farenzena, Michela and Fusiello, Andrea},
   year={2015},
   month=nov, pages={127–143} }

@misc{sfm_self_calibration2,
      title={Self-Calibration Supported Robust Projective Structure-from-Motion}, 
      author={Rui Gong and Danda Pani Paudel and Ajad Chhatkuli and Luc Van Gool},
      year={2020},
      eprint={2007.02045},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{li2019stereo,
      title={Stereo R-CNN based 3D Object Detection for Autonomous Driving}, 
      author={Peiliang Li and Xiaozhi Chen and Shaojie Shen},
      year={2019},
      eprint={1902.09738},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@Article{Peng_2020_CVPR,
author = {Peng, Wanli and Pan, Hao and Liu, He and Sun, Yi},
title = {IDA-3D: Instance-Depth-Aware 3D Object Detection From Stereo Vision for Autonomous Driving},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = June,
year = {2020}
}

@Article{attention_maps,
AUTHOR = {Ebert, Nikolas and Stricker, Didier and Wasenmüller, Oliver},
TITLE = {PLG-ViT: Vision Transformer with Parallel Local and Global Self-Attention},
JOURNAL = {Sensors},
VOLUME = {23},
YEAR = {2023},
NUMBER = {7},
ARTICLE-NUMBER = {3447},
URL = {https://www.mdpi.com/1424-8220/23/7/3447},
ISSN = {1424-8220},
DOI = {10.3390/s23073447}
}

@Article{bbox_mde,
AUTHOR = {Yu, Jongsub and Choi, Hyukdoo},
TITLE = {YOLO MDE: Object Detection with Monocular Depth Estimation},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {76},
URL = {https://www.mdpi.com/2079-9292/11/1/76},
ISSN = {2079-9292},
ABSTRACT = {This paper presents an object detector with depth estimation using monocular camera images. Previous detection studies have typically focused on detecting objects with 2D or 3D bounding boxes. A 3D bounding box consists of the center point, its size parameters, and heading information. However, predicting complex output compositions leads a model to have generally low performances, and it is not necessary for risk assessment for autonomous driving. We focused on predicting a single depth per object, which is essential for risk assessment for autonomous driving. Our network architecture is based on YOLO v4, which is a fast and accurate one-stage object detector. We added an additional channel to the output layer for depth estimation. To train depth prediction, we extract the closest depth from the 3D bounding box coordinates of ground truth labels in the dataset. Our model is compared with the latest studies on 3D object detection using the KITTI object detection benchmark. As a result, we show that our model achieves higher detection performance and detection speed than existing models with comparable depth accuracy.},
DOI = {10.3390/electronics11010076}
}

@misc{attention_vit,
      title={Emerging Properties in Self-Supervised Vision Transformers}, 
      author={Mathilde Caron and Hugo Touvron and Ishan Misra and Hervé Jégou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
      year={2021},
      eprint={2104.14294},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{retinanet,
      title={Focal Loss for Dense Object Detection}, 
      author={Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Dollár},
      year={2018},
      eprint={1708.02002},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{dota_dataset,
  author       = {Yu Yao and
                  Xizi Wang and
                  Mingze Xu and
                  Zelin Pu and
                  Ella M. Atkins and
                  David J. Crandall},
  title        = {When, Where, and What? {A} New Dataset for Anomaly Detection in Driving
                  Videos},
  journal      = {CoRR},
  volume       = {abs/2004.03044},
  year         = {2020},
  url          = {https://arxiv.org/abs/2004.03044},
  eprinttype    = {arXiv},
  eprint       = {2004.03044},
  timestamp    = {Wed, 08 Apr 2020 17:08:25 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2004-03044.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{ucsd,
  author={Li, Weixin and Mahadevan, Vijay and Vasconcelos, Nuno},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Anomaly Detection and Localization in Crowded Scenes}, 
  year={2014},
  volume={36},
  number={1},
  pages={18-32},
  keywords={Hidden Markov models;Computer vision;Image motion analysis;Computational modeling;Detectors;Feature extraction;Principal component analysis;Video analysis;surveillance;anomaly detection;crowded scene;dynamic texture;center-surround saliency},
  doi={10.1109/TPAMI.2013.111}}

@INPROCEEDINGS{avenue,
  author={Lu, Cewu and Shi, Jianping and Jia, Jiaya},
  booktitle={2013 IEEE International Conference on Computer Vision}, 
  title={Abnormal Event Detection at 150 FPS in MATLAB}, 
  year={2013},
  volume={},
  number={},
  pages={2720-2727},
  keywords={Silicon;Videos;Testing;Training;Surveillance;Training data;MATLAB;abnormal event detection;real-time;surveillance video;dictionary learning},
  doi={10.1109/ICCV.2013.338}}

  @article{shanghaitech_dataset,
  author       = {Wen Liu and
                  Weixin Luo and
                  Dongze Lian and
                  Shenghua Gao},
  title        = {Future Frame Prediction for Anomaly Detection - {A} New Baseline},
  journal      = {CoRR},
  volume       = {abs/1712.09867},
  year         = {2017},
  url          = {http://arxiv.org/abs/1712.09867},
  eprinttype    = {arXiv},
  eprint       = {1712.09867},
  timestamp    = {Thu, 03 Sep 2020 16:02:24 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1712-09867.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ucf_crime,
  author       = {Waqas Sultani and
                  Chen Chen and
                  Mubarak Shah},
  title        = {Real-world Anomaly Detection in Surveillance Videos},
  journal      = {CoRR},
  volume       = {abs/1801.04264},
  year         = {2018},
  url          = {http://arxiv.org/abs/1801.04264},
  eprinttype    = {arXiv},
  eprint       = {1801.04264},
  timestamp    = {Tue, 14 May 2019 16:43:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1801-04264.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{anticip_accident_dashcam,
  author       = {Fu-Hsiang Chan and
                  Yu-Ting Chen and
                  Yu Xiang and
                  Min Sun},
  title        = {Anticipating Accidents in Dashcam Videos},
  booktitle    = {Computer Vision -- ACCV 2016},
  year         = {2017},
  publisher    = {Springer International Publishing},
  address      = {Cham},
  pages        = {136--153},
  isbn         = {978-3-319-54190-7},
  editor       = {Shang-Hong Lai and
                  Vincent Lepetit and
                  Ko Nishino and
                  Yoichi Sato},
  timestamp    = {Tue, 14 May 2019 16:43:31 +0200},
  biburl       = {https://dblp.org/rec/conf/accv/ChanCXS16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{a3d,
  author       = {Yu Yao and
                  Mingze Xu and
                  Yuchen Wang and
                  David J. Crandall and
                  Ella M. Atkins},
  title        = {Unsupervised Traffic Accident Detection in First-Person Videos},
  journal      = {CoRR},
  volume       = {abs/1903.00618},
  year         = {2019},
  url          = {http://arxiv.org/abs/1903.00618},
  eprinttype    = {arXiv},
  eprint       = {1903.00618},
  timestamp    = {Sat, 30 Mar 2019 19:27:21 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1903-00618.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{dada1,
  author       = {Jianwu Fang and
                  Dingxin Yan and
                  Jiahuan Qiao and
                  Jianru Xue},
  title        = {{DADA:} {A} Large-scale Benchmark and Model for Driver Attention Prediction
                  in Accidental Scenarios},
  journal      = {CoRR},
  volume       = {abs/1912.12148},
  year         = {2019},
  url          = {http://arxiv.org/abs/1912.12148},
  eprinttype    = {arXiv},
  eprint       = {1912.12148},
  timestamp    = {Fri, 03 Jan 2020 16:10:45 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1912-12148.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{dada2,
  author       = {Jianwu Fang and
                  Dingxin Yan and
                  Jiahuan Qiao and
                  Jianru Xue and
                  He Wang and
                  Sen Li},
  title        = {{DADA-2000:} Can Driving Accident be Predicted by Driver Attention?
                  Analyzed by {A} Benchmark},
  journal      = {CoRR},
  volume       = {abs/1904.12634},
  year         = {2019},
  url          = {http://arxiv.org/abs/1904.12634},
  eprinttype    = {arXiv},
  eprint       = {1904.12634},
  timestamp    = {Thu, 02 May 2019 15:13:44 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1904-12634.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{bdd_a,
  author       = {Ye Xia and
                  Danqing Zhang and
                  Alexei Pozdnoukhov and
                  Ken Nakayama and
                  Karl Zipser and
                  David Whitney},
  title        = {Training a network to attend like human drivers saves it from common
                  but misleading loss functions},
  journal      = {CoRR},
  volume       = {abs/1711.06406},
  year         = {2017},
  url          = {http://arxiv.org/abs/1711.06406},
  eprinttype    = {arXiv},
  eprint       = {1711.06406},
  timestamp    = {Fri, 01 Oct 2021 08:58:32 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1711-06406.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{hasan_convae,
  author       = {Mahmudul Hasan and
                  Jonghyun Choi and
                  Jan Neumann and
                  Amit K. Roy{-}Chowdhury and
                  Larry S. Davis},
  title        = {Learning Temporal Regularity in Video Sequences},
  journal      = {CoRR},
  volume       = {abs/1604.04574},
  year         = {2016},
  url          = {http://arxiv.org/abs/1604.04574},
  eprinttype    = {arXiv},
  eprint       = {1604.04574},
  timestamp    = {Mon, 13 Aug 2018 16:47:36 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/0003CNRD16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{medel_lstmconvae,
  author       = {Yong Shean Chong and
                  Yong Haur Tay},
  title        = {Abnormal Event Detection in Videos using Spatiotemporal Autoencoder},
  journal      = {CoRR},
  volume       = {abs/1701.01546},
  year         = {2017},
  url          = {http://arxiv.org/abs/1701.01546},
  eprinttype    = {arXiv},
  eprint       = {1701.01546},
  timestamp    = {Mon, 13 Aug 2018 16:48:06 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/ChongT17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{luo_lstmconvae,

  author={Luo, Weixin and Liu, Wen and Gao, Shenghua},

  booktitle={2017 IEEE International Conference on Multimedia and Expo (ICME)}, 

  title={Remembering history with convolutional LSTM for anomaly detection}, 

  year={2017},

  volume={},

  number={},

  pages={439-444},

  keywords={Anomaly detection;Videos;Testing;Image reconstruction;Convolution;Three-dimensional displays;Neural networks;Anomaly detection;Convolutional Neural Networks;Long Short Term Memory},

  doi={10.1109/ICME.2017.8019325}}


@article{lowe_sift,
  author = {David G. Lowe},
  title = {Distinctive Image Features from Scale-Invariant Keypoints},
  journal = {International Journal of Computer Vision},
  volume = {60},
  number = {2},
  pages = {91--110},
  year = {2004},
  month = {11},
  abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
  issn = {1573-1405},
  doi = {10.1023/B:VISI.0000029664.99615.94},
  url = {https://doi.org/10.1023/B:VISI.0000029664.99615.94}
}

@incollection{ransac,
title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
editor = {Martin A. Fischler and Oscar Firschein},
booktitle = {Readings in Computer Vision},
publisher = {Morgan Kaufmann},
address = {San Francisco (CA)},
pages = {726-740},
year = {1987},
isbn = {978-0-08-051581-6},
doi = {https://doi.org/10.1016/B978-0-08-051581-6.50070-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780080515816500702},
author = {Martin A. Fischler and Robert C. Bolles},
abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced, RANSAC is capable of interpreting/ smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing and analysis conditions. Implementation details and computational examples are also presented.}
}

@article{asift,
    title   = {{ASIFT: An Algorithm for Fully Affine Invariant Comparison}},
    author  = {Yu, Guoshen and Morel, Jean-Michel},
    journal = {{Image Processing On Line}},
    volume  = {1},
    pages   = {11--38},
    year    = {2011},
    note    = {\url{https://doi.org/10.5201/ipol.2011.my-asift}}
}

@InProceedings{surf,
author="Bay, Herbert
and Tuytelaars, Tinne
and Van Gool, Luc",
editor="Leonardis, Ale{\v{s}}
and Bischof, Horst
and Pinz, Axel",
title="SURF: Speeded Up Robust Features",
booktitle="Computer Vision -- ECCV 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="404--417",
abstract="In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.",
isbn="978-3-540-33833-8"
}

@article{roc_auc_probabilistic,
  title={Measuring classifier performance: a coherent alternative to the area under the ROC curve},
  author={David J. Hand},
  journal={Machine Learning},
  year={2009},
  volume={77},
  pages={103-123},
  url={https://api.semanticscholar.org/CorpusID:207211591}
}

@INPROCEEDINGS{tran_3dconvnet,

  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},

  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 

  title={Learning Spatiotemporal Features with 3D Convolutional Networks}, 

  year={2015},

  volume={},

  number={},

  pages={4489-4497},

  keywords={Three-dimensional displays;Convolution;Kernel;Feature extraction;Solid modeling;Streaming media;Training},

  doi={10.1109/ICCV.2015.510}}

@misc{carreira_3dconvnet,
      title={Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset}, 
      author={Joao Carreira and Andrew Zisserman},
      year={2018},
      eprint={1705.07750},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1705.07750}, 
}

@misc{diba_3dconvnet,
      title={Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification}, 
      author={Ali Diba and Mohsen Fayyaz and Vivek Sharma and Amir Hossein Karami and Mohammad Mahdi Arzani and Rahman Yousefzadeh and Luc Van Gool},
      year={2017},
      eprint={1711.08200},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1711.08200}, 
}

@misc{gao_lstm_encoder,
      title={RED: Reinforced Encoder-Decoder Networks for Action Anticipation}, 
      author={Jiyang Gao and Zhenheng Yang and Ram Nevatia},
      year={2017},
      eprint={1707.04818},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1707.04818}, 
}

@misc{shou_gan,
      title={Online Detection of Action Start in Untrimmed, Streaming Videos}, 
      author={Zheng Shou and Junting Pan and Jonathan Chan and Kazuyuki Miyazawa and Hassan Mansour and Anthony Vetro and Xavier Giro-i-Nieto and Shih-Fu Chang},
      year={2018},
      eprint={1802.06822},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1802.06822}, 
}

@misc{huang_vivit,
      title={Towards Training Stronger Video Vision Transformers for EPIC-KITCHENS-100 Action Recognition}, 
      author={Ziyuan Huang and Zhiwu Qing and Xiang Wang and Yutong Feng and Shiwei Zhang and Jianwen Jiang and Zhurong Xia and Mingqian Tang and Nong Sang and Marcelo H. Ang Jr au2},
      year={2021},
      eprint={2106.05058},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2106.05058}, 
}

@misc{xu_pl_var,
      title={Cross-Model Pseudo-Labeling for Semi-Supervised Action Recognition}, 
      author={Yinghao Xu and Fangyun Wei and Xiao Sun and Ceyuan Yang and Yujun Shen and Bo Dai and Bolei Zhou and Stephen Lin},
      year={2022},
      eprint={2112.09690},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.09690}, 
}

@INPROCEEDINGS{zenc_enc_dec_ssl,
  author={Zeng, Ming and Yu, Tong and Wang, Xiao and Nguyen, Le T. and Mengshoel, Ole J. and Lane, Ian},
  booktitle={2017 IEEE International Conference on Big Data (Big Data)}, 
  title={Semi-supervised convolutional neural networks for human activity recognition}, 
  year={2017},
  volume={},
  number={},
  pages={522-529},
  keywords={Decoding;Semisupervised learning;Noise measurement;Legged locomotion;Activity recognition;Supervised learning;Data models;Human Activity Recognition;Deep Neural Networks;Semi-Supervised Learning;Convolutional Neural Networks},
  doi={10.1109/BigData.2017.8257967}}

@misc{yu_knowledge_distillation,
      title={Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes}, 
      author={Cheng-Yu Hsieh and Chun-Liang Li and Chih-Kuan Yeh and Hootan Nakhost and Yasuhisa Fujii and Alexander Ratner and Ranjay Krishna and Chen-Yu Lee and Tomas Pfister},
      year={2023},
      eprint={2305.02301},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.02301}, 
}
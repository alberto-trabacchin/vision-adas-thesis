\chapter{Introduction}
\pagenumbering{arabic}

\section{Focus of this work}

In the field of modern automotive technology, Advanced Driver Assistance Systems (ADAS) are playing a 
keyrole at augmenting driver safety, comfort, and overall driving experience. 
These systems, leveraging advancements in computer vision, sensor technologies, and artificial 
intelligence, are reshaping the automotive industry introducing semi-autonomous and autonomous driving 
capabilities.

According to the World Health organization (WHO) road traffic injuries are among the leading causes
of death worldwide, with an estimated 1.19 million fatalities annually.

With the aim of contributing to this transformative field, in this thesis various computer vision algorithms are implemented and 
evaluated, analyzing their strengths and weaknesses in addressing specific driving tasks.
From tracking of vulnerable users, such as pedestrians and cyclists, to the comprehension of dynamic 
driving environments, this research highlights advantages and limitations of each approach in real-world
scenarios.
Further considerations are made on the trade-offs between complexity of the tasks and available data to 
train the models. 

By scrutinizing the performance of these algorithms in real-world scenarios and carefully assessing their respective advantages and limitations, this thesis aims to provide valuable insights into their applicability and efficacy within the domain of advanced driver assistance systems (ADAS). Through this rigorous evaluation process, a nuanced understanding of the suitability of different computer vision techniques for specific driving tasks is achieved, paving the way for informed decision-making and future advancements in automotive safety and technology.

In the pursuit of contributing to this transformative field, this thesis endeavors to explore and implement a computer vision-based approach for ADAS systems. Specifically, the focus is on devising methodologies to enhance perception and decision-making capabilities within the realm of ADAS through the lens of computer vision.

This thesis is divided into two main approaches, each addressing distinct facets of ADAS functionality. The first approach revolves around a traditional computer vision methodology, leveraging principles of multiple view geometry and object tracking. By harnessing the fundamentals of geometric and visual analysis, this approach aims to provide robust and reliable solutions for tasks such as lane detection, object recognition, and tracking within the ADAS framework.

The second approach represents a departure from conventional techniques, delving into the realm of deep learning and vision transformers. Here, the emphasis shifts towards a more generalized approach to video-frame classification, leveraging the power of deep neural networks and semi-supervised learning techniques. By harnessing the capacity of vision transformers to capture intricate spatial and temporal features from raw video data, this approach seeks to push the boundaries of ADAS capabilities, particularly in scenarios involving complex and dynamic environments.

Through the amalgamation of these two distinct approaches, this thesis endeavors to contribute to the ongoing evolution of ADAS systems, striving towards the realization of safer, more efficient, and ultimately autonomous driving experiences. By exploring the synergy between traditional computer vision methodologies and cutting-edge deep learning techniques, this work aims to unlock new avenues for innovation and advancement within the realm of automotive technology.


\section{Thesis organization}
\thispagestyle{empty}
\section*{Abstract}
\vspace{0.5cm}
This thesis presents a comprehensive study on the development of a computer 
vision-based system for \acf{adas}. The research 
initially explored a classical computer vision approach, which involved 
employing detection and tracking algorithms and monocular depth estimation
to perceive the external environment. Moreover, the study focused on 
integrating the driverâ€™s attention state through its gaze projected from a pair 
of eye-tracking glasses onto the external scene, through a roof-mounted camera.
The primary objective was to analyze the driver's behavior by comparing 
its gaze with the locations of vulnerable road users, thereby proposing 
an initial safety scheme.

Despite the promising conceptual framework, it was observed that many of the 
conventional methods for extracting indirect features were not sufficiently 
robust in real-world driving scenarios. These methods struggled particularly 
under varying light conditions and during critical situations, highlighting 
significant limitations. In response to these challenges, the research 
transitioned to a fully deep learning-based approach. The core investigation centered 
on the capabilities of a Vision Transformer (ViT) in extracting human decision-making 
biases inherent in detecting dangerous driving situations.
The general idea is that humans classify dangerous situations based on their 
experience, knowledge and many other factors, which lead to different 
perspectives. Therefore, combining many of these perspectives, through labeled 
data, can help the model to learn a more general, and common, representation of 
the problem at hand. However, considering that labeled data is scarce in the 
literature and expensive to collect, the study started introducing an artificial 
bias. This bias is based on human labels of road scenes' objects; in particular, 
a scene was classified as dangerous if it contained a vulnerable road user, 
including pedestrians, cyclists, and motorcyclists. 
However, during training, the models were not informed about the bias, 
and they were expected to learn it by themselves.
This approach was further improved by 
employing semi-supervised learning techniques, which leverage the 
vast amounts of easily accessible unlabeled data, thus 
addressing the challenges associated with the expensive and labor-intensive 
labeling process.

We conducted a comprehensive analysis of the results from various perspectives, 
focusing on key evaluation metrics. Specifically, we tested the models using the 
Matthews Correlation Coefficient (MCC) and a custom cost function designed to 
minimize error. This approach was particularly effective in addressing the issue 
of unbalanced data, which is a common challenge in anomaly detection problems.

Moreover, the study opens up new challenges and opportunities for integrating 
large models with general knowledge, for improving task-specific applications, 
through the knowledge distillation process.
The study also discusses future 
research by identifying and addressing the challenges encountered during the 
development process. These findings underscore the critical role of computer 
vision in the advancement of \acs{adas}, emphasizing its significance in improving 
driver assistance systems through more accurate and reliable perception 
mechanisms.


\afterpage{\blankpage}

\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Smoothness and cluster assumptions. \textbf {Left}: The moon dataset representing smoothness between data points of each class. \textbf {Right}: The cluster assumption illustrated with a toy example.\relax }}{10}{}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Illustration of the manifold assumption. \textbf {Left}: Data points are distributed in a high-dimensional space. \textbf {Right}: The data points lie on a lower-dimensional manifold.\relax }}{10}{}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces The Vision Transformer architecture \blx@tocontentsinit {0}\cite {vit}. The input image is divided into fixed-size patches, linearly embedded, and positional embeddings are added. The resulting sequence of vectors is fed into the transformer encoder architecture. On the top a feed-forward layer performs the classification.\relax }}{13}{}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces svg image\relax }}{16}{}%
